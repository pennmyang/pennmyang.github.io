<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About Me</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Welcome to My Page</h1>
        </header>
        
        <main>
            <section class="about-section">
                <h2>About Me</h2>
                <div class="profile-content">
                    <div class="profile-text">
                        <p>Hello! I'm Mick</p>
                        <p>I'm currently completing a computer science master's (University of Pennsylvania) on a full scholarship (Good Ventures Foundation). Previously, I earned a law degree (Oxford University), worked in technical management (BCG X), and led data partnerships to help organizations effectively communicate their research (Kontinentalist).</p>

                        <p>I'm passionate about making AI development safer and more just and equitable. I focus on evaluations and related policies, but also explore other technical research agendas to try to cultivate a holistic view of developing AI safely.
                            <br>
                            Recent/current projects: 
                            <br>
                            [WIP] Leading a public-facing demo of AI automation threat model narrative for BlueDot Impact

                            <br>
                            [WIP] Working with Professor Chris Callison-Burch on improving multimodal training processes for vision-language models and reasoning models
                            
                            <br>
                            Wrote a paper on best practices for reporting model evaluations with Dr Anka Reuel (EU Working Group chair) and Dr Stephen Casper (AISI, MIT) 

                            <br>
                            Led a report with METR, SaferAI, AI Standards Lab comparing industry policies with the EU Code of Practice 

                            <br>
                            Contributed to Center for AI Safety benchmark/eval on advanced models' propensity to be honesty 
                          
                            <br>
                            Won Goodfire interpretability hackathon on domain-specific reasoning - developing ideas further, watch this space! [WIP]
                            </p>
                    </div>
                </div>
            </section>

            <section class="interests-section">
                <h2>My Interests</h2>
                <p> When I'm not working on AI safety technical governance and ML projects, you can find me:</p>
                <ul>
                    <li>Reading: current book is Walter Isaacson's biography of Leonardo Da Vinci. Eager to read "Heart Lamp" next!</li>
                    <li>Food-hunting: Friends say I have a high hit rate of finding high value-for-money 'hidden gem' type eateries, and I love to share this with others!</li>
                    <li>Organizing stuff: I love to organize people to do stuff, whether it's for a fun social experience or an ambitious project</li>
                </ul>
            </section>

            <section class="contact-section">
                <h2>Get in Touch</h2>
                <div class="social-links">
                    <a href="https://github.com/pennmyang" target="_blank">GitHub</a>
                    <a href="https://linkedin.com/in/mick_yang" target="_blank">LinkedIn</a>
                    <a href="mailto:mickyang@seas.upenn.edu">Email</a>
                </div>
            </section>
        </main>

        <footer>
            <p>Â© 2024 Mick Yang. All rights reserved.</p>
        </footer>
    </div>
</body>
</html> 